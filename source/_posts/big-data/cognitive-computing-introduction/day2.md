---
title: 机器学习概述
date: 2022-05-13 16:04:38
math: true
categories:
 - [大数据,计算智能]
tags: 
 - 大数据
 - 计算智能
---

# 根据学习方式分类

- 监督学习：给定训练样本，每个样本的输入$x$都对应一个确定的结果$y$，需要训练出一个模型(数学上看是一个$x\rightarrow y$的映射关系$f$), 在未知的样本$x'$给定后，能对结果$y'$做出预测。
- 无监督学习：在样本中抽取出通用规则，关联规则和聚类算法在内的一系列机器学习算法都是无监督学习。
- 半监督学习：如自训练、直推学习、生成式模型

# 根据算法功能分类

- 回归算法通过最小化预测值与实际结果值之间的差距，来得到输入特征之间的最佳组合方式。对连续值的预测有线性回归算法，对离散值或类别预测有逻辑回归算法。
- 基于实例的算法：指最后建成的模型，对原始数据样本依旧有很强的依赖性。
- 基于规则的算法：回归算法的拓展
- 决策树分类算法：基于原始数据特征，构建一棵包含很多决策路径的树。预测阶段选择路径进行决策。
- 贝叶斯类算法
- 聚类算法
- 关联规则算法
- 人工神经网络算法
- 深度学习算法
- 支持向量机算法
- 组合算法


# 机器学习主要算法

## 决策树

常见的构造决策树的方法有ID3算法、C4.5算法和CART算法。

**ID3算法**
核心思想：以属性的信息增益作为度量，选择分裂后信息增益最大的属性进行分类，使得每个分支上的输出分区尽可能都属于同一类。
**C4.5**
C4.5算法是ID3的改进算法，为了防止训练集的过度拟合

## 基于规则的分类

基于规则的分类器使用一组“if...then...”规则来分类记录的技术，通常采用析取范式的方式来表示模型的规则：
$$R=(r_{1} \vee r_{2} \dots \vee r_{k})$$
式中：R称为规则集；$r_{i}$是分类规则或析取项。

## 最邻近分类

Rote分类工作原理：当测试数据实例和某个训练集实例完全匹配时才对其分类。
缺点：大部分测试集实例由于没有任何训练集实例与之匹配而没法进行分类。
一种改进模型是：最近邻分类器
找出与测试样例属性相对较近的所有训练数据集实例。
最常用的是欧式距离：
$$d(x,y)=\sum_{k=1}^{n}|x_{k}-y_{k}|$$

## 支持向量机

支持向量机SVM是一种对线性和非线性数据进行分类的方法

## 朴素贝叶斯

应用场景：属性集和类变量之间的关系不确定。也就是说，尽管测试记录的属性集合某些训练样例相同，但是也不能确定地预测它的类标号，需要利用一些不确定来进行建模分析。
$X$和$Y$的联合概率和条件概率满足下列关系：
$$P(x,Y)=P(Y|X)\times P(X) = P(X|Y) \times P(Y)$$
贝叶斯定理：
$$P(Y|X)= \frac{P(X|Y)P(Y)}{P(X)}$$

## 随机森林

组合分类：聚集多个分类器的预测来提高分类准确率。
随机森林是一类专门为决策树分类器设计的组合方法。组合多颗决策树做出预测，其中每棵树都是基于随机向量的一个独立集合的值产生的。
Forest—RI随机森林决策方法：通过随机属性得到一个随机向量，再利用该随机向量来构建决策树，一旦决策树构建完成，就利用多数表决的方法来组合预测。
这种方法得到的随机森林决策强度取决于随机向量的维数，也就是每一棵树选取的特征数个数$F$，通常取
$$F = log_2d+1$$
$d$为总属性个数。

## 聚类分析

无监督学习的典型算法
原理：将数据划分成有意义或有用的组(簇)。
三种聚类技术：$K$-均值、凝聚层次聚类和基于密度聚类(DBSCAN)
$$ X=\cup_{i=1}^{n}X_{i}, X_{i}\cap X_{j}=\emptyset(i  \neq j)$$

## 聚类方法

1、K-均值聚类

簇心：
$$\overline{x_{C_{i}}}=\frac{\sum_{i=1}^{n_{i}}\overrightarrow{x_{i}}}{n_{i}}, i = 1,2,...,k$$
$n_{i}$为簇中元素个数；$\overrightarrow{x_{i}}$为簇中元素向量坐标；$\overrightarrow{x_{C_{i}}}$代表簇$C_{i}$
目标函数：
$$ E = \sum_{i=1}^{k}\sum_{x\in C_{i}}[d(x,\overline{x_{C_{i}}})]^2$$
$d(x,y)$表示两个向量之间的欧式距离。
目标函数$E$是数据集$D$中所有对象到簇心的误差平方和。

K-均值目标：对于给定的数据集合和给定的$k$，找到一组簇$C_{1}, C_{2},...,C_{k}$，使得目标函数$E$最小。

2、凝聚层次聚类
$K$-均值聚类是根据已经给定的簇个数，将原始数据对象向各个簇聚拢，最终得到聚类结果；而层次聚类不需要给定类别个数，它是从每个对象出发，根据对象的邻近矩阵逐渐聚拢各个对象，直到所有对象都归为一类为止(或者从整体出发，逐渐分离各对象，直到每个对象都是一类)。层次分类划分为以下两类：
1、凝聚层次聚类：从个体对象为簇出发，每次合并两个最邻近的对象或簇，直到所有对象都在一个簇中(即数据全体集合)
2、分裂层次聚类：从包含所有点的簇开始(即数据全体集合)，每次分裂一个簇得到距离最远的两个簇，直到不能再分裂(只剩下单点簇)。
5种定义邻近度方式：单链、全链、组平均、Ward法和质心法。

3、基于密度的聚类
将空间数据根据数据的密集程度划分成不同的区域，而每个区域对应于某个簇，将离群点离开。
- 核心点：稠密区域内部的点
- 边界点：稠密区域边缘上的点。
- 噪声点：稀疏区域中的点。

