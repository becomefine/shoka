---
title: 支持向量机
date: 2022-06-01 09:24:38
categories:
 - [机器学习,机器学习]
tags: 
 - 机器学习
 - 机器学习算法
 - 周志华
---

# 支持向量机

## 间隔与支持向量

划分超平面通过线性方程：
$$ \vec{w}^{T}\vec{x} + b = 0 (6.1)$$

其中$\vec{w}=(w_{1};w_{2};...;w_{d})$为法向量，决定了超平面的方向；b为位移项，决定了超平面与原点之间的距离。
样本空间中任意点$\vec{x}$到超平面$(\vec{w},b)$的距离可写为
$$
r = \frac{| \vec{w}^{T} \vec{x} + b|}{||\vec{w}||}
$$
![support](/assets/machine-learning/machine-learning/support-vector.jpg)

距离超平面最近的几个训练样本点为“支持向量”(support vector), 两个异类支持向量到超平面的距离之和为
$$ \gamma = \frac{2}{||\vec{w}||}
$$
欲找到具有“最大间隔”的划分超平面，也就是要找到能满足式中约束的参数$\vec{w}$和b，使得$\gamma$最大，即

$$\begin{aligned}
max_{\vec{w},b} \\
s.t. y_{i}(\vec{w^{T}\vec{x}_{i}}+b) \geq 1, i = 1,2,...,m.
\end{aligned}
$$

为了最大化间隔，仅需最大化$||\vec{w}||^{-1}$, 这等价于最小化

## 核函数

将样本从原始空间映射到一个更高维的特征空间，使得样本在这个特征空间内线性可分。如果原始空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分。
令$\phi(\vec{x})$表示将$\vec{x}$映射后的特征向量，在特征空间中划分超平面所对应的模型可表示为：
$$ f(\vec{x}) = \vec{w}^{T} \phi(\vec{x}) + b$$
其中$\vec{w}$和$b$是模型参数。


