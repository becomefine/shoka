---
title: 模型评估与选择
math: true
date: 2022-05-12 17:48:32
categories:
 - [机器学习,机器学习]
tags: 
 - 机器学习
 - 机器学习算法
 - 周志华
---

# 模型评估与选择

## 经验误差与过拟合

错误率$E = a/m$, 即如果在$m$个样本中有$a$个样本分类错误。
精度$1-a/m$, 即精度 = 1 - 错误率
**误差**：学习器的实际预测输出与样本的真实输出之间的差异

**欠拟合**，学习能力低下
解决方法：在决策树学习中扩展分支、在神经网络学习中增加训练轮数。

**模型选择问题(model selection)**
理想的解决方案是对候选模型的泛化误差进行评估，然后选择泛化误差最小的那个模型。

## 评估方法

### 留出法

留出法(hold-out)直接将数据集D划分为两个互斥的集合，其中一个集合作为训练集$S$，另一个作为测试集$T$，即$D = S \bigcup T, S \bigcap T = \emptyset$, 在$S$上训练出模型后，用$T$来评估其测试性能误差，作为对泛化误差的估计。
训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中至少要保持样本的类别比例相似。
单次使用留出法得到的估计结果往往不够稳定可靠，在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作为留出法的评估结果。
常见做法是将大约$2/3 ~ 4/5$的样本用于训练，剩余样本用于测试。

### 交叉验证法

交叉验证法(cross validation)先将数据集$D$划分为$k$个大小相似的互斥子集，即$D = D_{1} \bigcup D_{2} \bigcup \dots \bigcup D_{k}$, $D_{i} \bigcap D_{j} = \empty (i \neq j)$, 每个子集$D_{i}$都尽可能保持数据分布的一致性，即从$D$中通过分层采样得到。然后用$k-1$个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得$k$组训练/测试集，从而可进行$k$次训练和测试，最终返回的是这$k$个测试结果的均值。
交叉验证法评估结果的稳定性和保真性很大程度上取决于$k$的取值。通常把交叉验证法成为"$k$折交叉验证"($k$fold cross validation)
$k$最常用的取值是10，此时称为10折交叉验证。

### 自助法

减少训练样本规模不同造成的影响，同时还能比较高效地进行实验估计。
自助法以自助采样法(bootstrap sampling)为基础。给定包含$m$个样本的数据集$D$，我们对它进行采样产生数据集$D'$: 每次随机从$D$中挑选一个样本，将其拷贝放入$D'$，然后再将该样本放回初始数据集$D$中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行$m$次后，我们就得到了包含$m$个样本的数据集$D'$, 显然，$D$中有一部分样本会在$D'$中多次出现，而另一部分样本不出现，样本在$m$次采样中始终不被采到的概率是$(1-\frac{1}{m})^{m}$, 取极限得到
$$ \lim_{n\to\infty}(1-\frac{1}{m})^{m} = \frac{1}{e} \approx 0.368 $$

即通过自助采样，初始数据集$D$中约有$%36.8%$的样本未出现在采样数据集$D'$中，于是我们可将$D'$用作训练集，$D\D'$用作测试集；这样，实际评估的模型与期望评估的模型都使用$m$个训练样本，而我们仍有数据总量约$1/3$的、没在训练集中出现的样本用于测试，这样的测试结果，亦称“包外估计(out of bag estimate)”。
自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处。然而，自助法产生的数据集改变了初始数据集的分布，这会引入引入估计误差，因此，在初始数据量足够时，留出法和交叉验证法更常用一些。

### 调参与最终模型

选定参数的做法：对每个参数选定一个范围和变化步长，例如在[0,0.2]范围内以0.05为步长，则实际要评估的候选参数值有5个，最终是从这5个候选值中产生选定值。
显然，这样选定的参数值往往不是“最佳”值，但这是在计算开销和性能估计之间进行折中的结果。
:::warning no-icon
通常把学得模型在实际使用中遇到的数据称为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验证集”(validation set)。例如，在研究对比不同算法的泛化性能时，我们用测试集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为训练集合验证集，基于验证集上的性能来进行模型选择和调参。
:::

## 性能度量

给定样例集$D = {(x_{1},y_{1}),(x_{2},y_{2}),\dots,(x_{m},y_{m})}$, 其中$y_{i}$是示例$x_{i}$的真实标记，要评估学习器$f$的性能，就要把学习器预测结果$f(x)$与真实标记$y$进行比较。
回归任务最常用的性能度量是“均方误差”(mean squared error)
$$ E(f;D) = \frac{1}{m} \sum_{i=1}^{m}(f(x_{i}-y_{i})^2) $$
更一般的，对于数据分布$D$和概率密度函数$p(·)$, 均方误差可描述为
$$ E(f;D) = \int_{x~D}(f(x)-y)^2p(x)dx$$

### 错误率与精度

错误率: $E(f;D) = \frac{1}{m}\sum_{i=1}^{m}\prod (f(x_{i}) \neq y_{i})$
精度：$acc(f;D) = 1 - E(f;D)$

### 查全率与查准率与F1

tabel2.1 分类结果混淆矩阵
{% raw %}
<table>
    <tr>
        <td rowspan = "2">真实情况</td>
        <td colspan = "2" style='text-align:center'>预测结果</td>
    </tr>
    <tr>
        <td>正例</td>
        <td>反例</td>
    </tr>
    <tr>
        <td>正例</td>
        <td>TP(真正例)</td>
        <td>FN(假反例)</td>
    <tr>
    <tr>
        <td>反例</td>
        <td>FP(假反例)</td>
        <td>TN(真反例)</td>
    </tr>
</table>
{% endraw %}

查准率：
$$ P = \frac{TP}{TP+FP}$$
查全率：
$$ R = \frac{TP}{TP+FN}$$

查准率和查全率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，而查全率高时，查准率往往偏低。
![machine](/assets/machine-learning/machine-learning/pr.jpg)
P-R图直观地显示出学习器在样本总体上的查全率、查准率。
“平衡点(Break-Even Point, 简称BEP)”是“查全率=查准率”时的取值。
BEP过于简化，更常用的是$F1$度量：
$$ F1 = \frac{2 \times P\times R}{P+R}=\frac{2 \times TP}{样例总数 + TP-TN}$$


$F1$度量的一般形式——$F_{\beta}$, 可以表达出对查准率/查全率的不同偏好：
$$ F_{\beta} = \frac{(1+\beta^{2}) \times P \times R}{(\beta^{2} \times P) + R} $$
其中$\beta > 0$度量了查全率对查准率的相对重要性。$\beta=1$为退化标准的$F1$, $\beta > 1$时查全率有更大影响；$\beta < 1$时查全率有更大影响。

### ROC和AUC

ROC受试者工作特征(Receiver Operating Characteristic)曲线：
纵轴：真正例率(True Positive Rate 简称TPR)
横轴: 假正例率(False Positive Rate 简称FPR)
$$ TPR = \frac{TP}{TP+FN} (2.18)$$
$$ FPR = \frac{FP}{TN+FP} (2.19)$$

![machine](/assets/machine-learning/machine-learning/roc1.jpg)

### 代价敏感错误率与代价曲线
{% raw %}
<table>
    <tr>
        <td rowspan = "2">真实类别</td>
        <td colspan = "2" style='text-align:center'>预测结果</td>
    </tr>
    <tr>
        <td>第0类</td>
        <td>第1类</td>
    </tr>
    <tr>
        <td>第0类</td>
        <td>0</td>
        <td>cost01</td>
    <tr>
    <tr>
        <td>第1类</td>
        <td>cost10</td>
        <td>0</td>
    </tr>
</table>
{% endraw %}
